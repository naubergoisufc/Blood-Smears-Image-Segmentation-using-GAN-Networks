\subsection{Convolutional Neural Networks}

Convolutional Neural Networks (CNNs) are able to map complex, high-dimensional image data into a much lower dimensional space of finite distinct categories, composed of hundreds or thousands object classes. Categories may be smoothly different, as presented in a possible distinction of a Siberian Husky and an Eskimo dog (Figure \ref{fig:husky}). 

\begin{figure*}[!h]
\caption{Siberian Husky X Eskimo dog}
\label{fig:husky}
  \includegraphics[width=\textwidth]{images/husky.jpg}
\end{figure*}

Their architecture consists basically of a stack of three types of layers, namely convolutional layers, pooling layers, and fully-connected layers. A typical CNN network is depicted in Figure \ref{fig:mnist}. A convolutional layer determines the output of neurons associated with local regions of the input, by means of the scalar product between their weights and the region representing the input volume. The ReLu (rectified linear unit) rectifier applies an element-wise activation function (eg. sigmoid) to the output of the activation generated by the previous layer. A pooling layer, in turn,  downsamples along the spatial dimensionality of the input, thus reducing the number of parameters in the current activation. Finally, a fully-connected layer is responsible for producing class scores from activations, for classification purposes. For improving performance, ReLu is also commonly employed between these layers. 


\begin{figure*}[!h]
\caption{Standard CNN architecture}
\label{fig:mnist}
  \includegraphics[width=\textwidth]{images/CNN.png}
\end{figure*}

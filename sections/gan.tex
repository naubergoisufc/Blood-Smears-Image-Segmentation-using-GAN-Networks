\subsection{Generative Adversarial Networks}

Learning reusable resource representations from large datasets has been an active research area. One way to build good image representations is through Generative Adversarial Networks. Generator Adverse Networks (GAN) learn to synthesize elements of a target distribution using two competing neural networks. GAN networks can produce compelling images that are sharper than those produced by automatic encoders using pixel losses. The Generator (G) network selects an n-dimensional random sample from a predefined distribution, conventionally called latent space and attempts to create examples of the target distribution. The discriminant network (D) takes a generated or real example as input and has to make the binary decision whether the input is real or generated. This competition process is expressed as a zero-sum game in the following loss term:

Let $x$ be a natural image taken from a distribution $ p_X$ and $ z \in {\rm I\!R}^d $ be a random vector. Considering that $z$ has a uniform distribution with support $[1,-1]^d$, then $g$ and $f$ are the generator and discriminative models, respectively. Denoting the distribution $g(z)$ to $ p_G $. The discriminative model estimates the probability that an input image was generated by $ p_X $. Ideally, $f(x)=1$  if $x  \sim\  p_X$ and $f (x) = 0$ if $ x \sim\ p_G $. A GAN network corresponds to the generator and discriminative models, trained according to the equation \cite{Liu2016}:


\begin{equation}
\medmath{ \underset{g}{max} \underset{f}{min} V(f,g)= \mathbb{E}_{x \sim px} [-log(f(x))]+\mathbb{E}_{z \sim pz}[-log(1-f(g(z)))]} \nonumber 
\end{equation}

The equation above is solved by applying the gradient in two steps:

\begin{equation}
\theta^{t+1}_{f} = \theta^{t}_{f} -\lambda^t \nabla_{\theta f} V (f^t, g^t) \nonumber
\end{equation}

\begin{equation}
\theta^{t+1}_{g} = \theta^{t}_{g} -\lambda^t \nabla_{\theta g} V (f^t+1, g^t) \nonumber
\end{equation}


$ \theta_f $ and $ \theta_g $ are parameters of $f$ and $g$, $ \ lambda $ is the learning rate and t is the number of iterations.

Goodfellow et al. show that given sufficient capacity for f and g training iterations, the distribution $ p_G $ converges to $ p_X $. In other words, from a random vector $z$, the network $g$ can synthesize an image $g (z)$ that resembles one that is extracted from the true distribution $ p_X $ \cite{Goodfellow2014}.